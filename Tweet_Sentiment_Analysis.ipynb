{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpGyR-YI5b0G"
   },
   "source": [
    "#Import Tweets Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJoupv7u5en8"
   },
   "source": [
    "\n",
    "1.   Import Tweets from sntwitter API (https://github.com/JustAnotherArchivist/snscrape)\n",
    "\n",
    "2.   Clean up data - Remove special characters, emojis, memes in each tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.bfsu.edu.cn/pypi/web/simple\n",
      "Requirement already satisfied: snscrape in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (0.3.4)\n",
      "Requirement already satisfied: lxml in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (from snscrape) (4.5.2)\n",
      "Requirement already satisfied: requests[socks] in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (from snscrape) (2.24.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (from snscrape) (4.9.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape) (2.10)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape) (1.7.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4->snscrape) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TL4hnDjRfBdJ",
    "outputId": "a783ec45-a8b1-42f6-d04c-e4767364c4a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.bfsu.edu.cn/pypi/web/simple\n",
      "Requirement already satisfied: snscrape in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (0.3.4)\n",
      "Requirement already satisfied: lxml in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (from snscrape) (4.5.2)\n",
      "Requirement already satisfied: requests[socks] in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (from snscrape) (2.24.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (from snscrape) (4.9.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape) (1.25.9)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape) (1.7.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4->snscrape) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "import matplotlib.pyplot as mlpt\n",
    "import csv\n",
    "#pip install snscrape\n",
    "!pip install snscrape\n",
    "import datetime as dt\n",
    "import snscrape.modules.twitter as sntwitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = []\n",
    "extreme_positive = []\n",
    "positive = []\n",
    "neutral = []\n",
    "negative = []\n",
    "extreme_negative = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import contractions\n",
    "from contractions import contractions_dict\n",
    "import re\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from autocorrect import spell\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "def expand_contractions(text, contractions_dict):\n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contractions_dict.keys())),\n",
    "                                      flags=re.IGNORECASE | re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contractions_dict.get(match) \\\n",
    "            if contractions_dict.get(match) \\\n",
    "            else contractions_dict.get(match.lower())\n",
    "        expanded_contraction = expanded_contraction\n",
    "        return expanded_contraction\n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "def stemmer(text):\n",
    "    # Lancaster Stemmer\n",
    "    ls = LancasterStemmer()\n",
    "    #snowball stemmer\n",
    "    #ss = SnowballStemmer()\n",
    "    text = ' '.join([ls.stem(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text\n",
    "\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "def remove_stopwords(text, stopwords=stopword_list):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "def spell_check(text):\n",
    "    spelled_text = [spell(w) for w in (nltk.word_tokenize(text))]\n",
    "    return spelled_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_string(s):\n",
    "    \n",
    "    #Lower case\n",
    "    #s = s.lower()\n",
    "    #remove HTML\n",
    "    s = re.sub('<[^<]+?>','', s)\n",
    "    #remove numbers\n",
    "    s = ''.join(c for c in s if not c.isdigit())\n",
    "    #expand contractions \n",
    "    #s = expand_contractions(remove_accented_chars(s),contractions_dict)\n",
    "    ##s = remove_accented_chars(s)\n",
    "    # remove extra newlines\n",
    "    s = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',s)\n",
    "    #remove special characters\n",
    "    s = remove_special_characters(s)\n",
    "    s = re.sub('_', ' ', s)\n",
    "    # remove extra whitespace\n",
    "    s = re.sub(' +', ' ', s)\n",
    "    #Remove stopwords\n",
    "    s = remove_stopwords(s)\n",
    "    #Lemmatize\n",
    "    #s = lemmatize_text(s)\n",
    "    #spell check\n",
    "    #s = spell_check(s)\n",
    "    #print(1)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "HkOBULwofJWg"
   },
   "outputs": [],
   "source": [
    "tweets = []\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#rhino  since:2021-01-01 until:2021-10-10','corona lang:en').get_items()):\n",
    "    tweets.append([tweet.date,  tweet.content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NnN8TgDXxroy"
   },
   "outputs": [],
   "source": [
    "tweets = pd.DataFrame(tweets, columns=['Date', 'Tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "76LJY2Z-vxaU"
   },
   "outputs": [],
   "source": [
    "data=tweets\n",
    "cdata=pd.DataFrame(columns=['Date','Tweets'])\n",
    "index=0\n",
    "for index,row in data.iterrows():\n",
    "    stre=row[\"Tweets\"]\n",
    "    my_new_string = re.sub('[^ a-zA-Z0-9]', '', stre)\n",
    "    cdata.sort_index()\n",
    "    cdata.at[index,'Date']=row[\"Date\"]\n",
    "    cdata.at[index,'Tweets']=my_new_string\n",
    "    index=index+1\n",
    "tweets=cdata\n",
    "tweets['Date'] = tweets['Date'].astype('datetime64[ns]')\n",
    "tweets[\"Date\"]=tweets[\"Date\"].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "61s2fPu6TT9c",
    "outputId": "cc99ca1d-1020-46d9-a36c-5521d36eaa35"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-09</td>\n",
       "      <td>New post  httpstcoiTXpkxzT31 art cartoon  Digi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-09</td>\n",
       "      <td>Finished making RhinoDragon20 as a Nintendo Mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-09</td>\n",
       "      <td>Happy birthday to the man beast rhyno themanbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-09</td>\n",
       "      <td>Electing the wrong people to power and creatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-09</td>\n",
       "      <td>Great job by Rhino ReinhardtCole FutureSen Bel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11097</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Good Morning from Chitwan National Park wildli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11098</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>These things are a little different  chiapparh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11099</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Introducing the Elasmotheriumelasmotherium mam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11100</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Every time we sit down for dinner if you look ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11101</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Rhynuke a Steeltype Fakemon Fakemon Steel Rhin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11102 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date                                             Tweets\n",
       "0      2021-10-09  New post  httpstcoiTXpkxzT31 art cartoon  Digi...\n",
       "1      2021-10-09  Finished making RhinoDragon20 as a Nintendo Mi...\n",
       "2      2021-10-09  Happy birthday to the man beast rhyno themanbe...\n",
       "3      2021-10-09  Electing the wrong people to power and creatin...\n",
       "4      2021-10-09  Great job by Rhino ReinhardtCole FutureSen Bel...\n",
       "...           ...                                                ...\n",
       "11097  2021-01-01  Good Morning from Chitwan National Park wildli...\n",
       "11098  2021-01-01  These things are a little different  chiapparh...\n",
       "11099  2021-01-01  Introducing the Elasmotheriumelasmotherium mam...\n",
       "11100  2021-01-01  Every time we sit down for dinner if you look ...\n",
       "11101  2021-01-01  Rhynuke a Steeltype Fakemon Fakemon Steel Rhin...\n",
       "\n",
       "[11102 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"Tweets\"] =tweets[\"Tweets\"].apply(lambda x: normalize_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"Tweets\"] = tweets[\"Tweets\"].apply(lambda x: ' '.join(word for word in x.split(' ') if not word.startswith('http')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-09</td>\n",
       "      <td>New post art cartoon DigitalIllustration eanim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-09</td>\n",
       "      <td>Finished making RhinoDragon Nintendo MiiIts ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-09</td>\n",
       "      <td>Happy birthday man beast rhyno themanbeastrhyn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-09</td>\n",
       "      <td>Electing wrong people power creating kleptocra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-09</td>\n",
       "      <td>Great job Rhino ReinhardtCole FutureSen Bellev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11097</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Good Morning Chitwan National Park wildlife ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11098</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>These things little different chiapparhino rhi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11099</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Introducing Elasmotheriumelasmotherium mammal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11100</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Every time sit dinner look see frenchbulldogs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11101</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Rhynuke Steeltype Fakemon Fakemon Steel Rhino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11102 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date                                             Tweets\n",
       "0      2021-10-09  New post art cartoon DigitalIllustration eanim...\n",
       "1      2021-10-09  Finished making RhinoDragon Nintendo MiiIts ba...\n",
       "2      2021-10-09  Happy birthday man beast rhyno themanbeastrhyn...\n",
       "3      2021-10-09  Electing wrong people power creating kleptocra...\n",
       "4      2021-10-09  Great job Rhino ReinhardtCole FutureSen Bellev...\n",
       "...           ...                                                ...\n",
       "11097  2021-01-01  Good Morning Chitwan National Park wildlife ch...\n",
       "11098  2021-01-01  These things little different chiapparhino rhi...\n",
       "11099  2021-01-01  Introducing Elasmotheriumelasmotherium mammal ...\n",
       "11100  2021-01-01  Every time sit dinner look see frenchbulldogs ...\n",
       "11101  2021-01-01      Rhynuke Steeltype Fakemon Fakemon Steel Rhino\n",
       "\n",
       "[11102 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv('2021-1031.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#rhino  since:2019-01-01 until:2019-12-31','corona lang:en').get_items()):\n",
    "    tweets.append([tweet.date,  tweet.content])\n",
    "    \n",
    "tweets = pd.DataFrame(tweets, columns=['Date', 'Tweets'])\n",
    "data=tweets\n",
    "cdata=pd.DataFrame(columns=['Date','Tweets'])\n",
    "index=0\n",
    "for index,row in data.iterrows():\n",
    "    stre=row[\"Tweets\"]\n",
    "    my_new_string = re.sub('[^ a-zA-Z0-9]', '', stre)\n",
    "    cdata.sort_index()\n",
    "    cdata.at[index,'Date']=row[\"Date\"]\n",
    "    cdata.at[index,'Tweets']=my_new_string\n",
    "    index=index+1\n",
    "tweets=cdata\n",
    "tweets['Date'] = tweets['Date'].astype('datetime64[ns]')\n",
    "tweets[\"Date\"]=tweets[\"Date\"].dt.date\n",
    "\n",
    "tweets[\"Tweets\"] =tweets[\"Tweets\"].apply(lambda x: normalize_string(x))\n",
    "tweets[\"Tweets\"] = tweets[\"Tweets\"].apply(lambda x: ' '.join(word for word in x.split(' ') if not word.startswith('http')))\n",
    "\n",
    "tweets.to_csv('2019-1231.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('2019-1031.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    " \n",
    " #读取news_data.csv，保存到新建的news_data.txt中\n",
    "with open('rhino_2021.txt','a+', encoding='utf-8') as f:\n",
    "    for line in tweets.values:\n",
    "        if 'RhinoGirls' not in str(line[2]) and 'amp' not in str(line[2]) and 'Mulch' not in str(line[2]):\n",
    "            f.write((str(line[2])+'\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N13nzV7Bzmdz"
   },
   "source": [
    "#Sentiment Analysis for Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N78XHzHZ7YTD"
   },
   "source": [
    "Sentiment Analysis is a process of ‘computationally’ evaluating whether a piece of text is positive, negative or neutral. In our case, conducting sentiment analysis on tweets help determine the public's moods towards BLM(Black Lives Matter) topic.\n",
    "1.   **VADER (Valence Aware Dictionary and Entiment Reasoner)**\n",
    "\n",
    "```\n",
    "\"VADER is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed\n",
    "in social media. A sentiment lexicon is a list of lexical features (e.g., words) which are generally labeled\n",
    "according to their semantic orientation aseither positive or negative. VADER not only tells about the Positivity\n",
    "and Negativity score but also tells us about how positive or negative a sentiment is.\" (GreeksforGreeks)\n",
    "```\n",
    "2.   **Reference**\n",
    " \n",
    "  Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.bfsu.edu.cn/pypi/web/simple\n",
      "Requirement already satisfied: vaderSentiment in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (from vaderSentiment) (2.24.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (from requests->vaderSentiment) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (from requests->vaderSentiment) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (from requests->vaderSentiment) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (from requests->vaderSentiment) (2020.6.20)\n",
      "Looking in indexes: https://mirrors.bfsu.edu.cn/pypi/web/simple\n",
      "Requirement already satisfied: pyspark in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (3.1.2)\n",
      "Requirement already satisfied: py4j==0.10.9 in /Users/aoziqiao/opt/anaconda3/lib/python3.8/site-packages (from pyspark) (0.10.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment\n",
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark as spark\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import col,udf,monotonically_increasing_id,unix_timestamp,round,avg\n",
    "import re\n",
    "sc = spark.SparkContext()\n",
    "sql = spark.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('2014-1231.csv')\n",
    "tweets = tweets.dropna().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets1['type']  = tweets1['Tweets'].apply(lambda x: 0 if type(x)==str else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34686</th>\n",
       "      <td>34686</td>\n",
       "      <td>2014-06-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        Date Tweets  type\n",
       "34686       34686  2014-06-24    NaN     1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets1[tweets1['type']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_calculation(data):\n",
    "    #tweets = pd.read_csv(file)\n",
    "    FullDataTw=sql.createDataFrame(data)\n",
    "    FullDataTw = FullDataTw.dropna()\n",
    "    FullDataTw.select(monotonically_increasing_id().alias(\"rowId\"),\"*\")\n",
    " #setting column names of Twitter dataset\n",
    "    CleanDF = FullDataTw.withColumnRenamed('Tweets', 'Tweet')\n",
    "    CleanDF = FullDataTw.withColumnRenamed('Date', 'Date_Time')\n",
    "    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "    def senti_score_udf(sentence):\n",
    "        snt = analyser.polarity_scores(sentence)\n",
    "        return ([snt['neg'], snt['neu'], snt['pos'], snt['compound']])\n",
    "    func_udf2 = udf(senti_score_udf, ArrayType(FloatType()))\n",
    "    CleanDF = CleanDF.withColumn('p_neg', func_udf2(CleanDF['Tweets'])[0])\n",
    "    CleanDF = CleanDF.withColumn('p_neu', func_udf2(CleanDF['Tweets'])[1])\n",
    "    CleanDF = CleanDF.withColumn('p_pos', func_udf2(CleanDF['Tweets'])[2])\n",
    "    CleanDF = CleanDF.withColumn('p_comp', func_udf2(CleanDF['Tweets'])[3])\n",
    "    #CleanDF.show(120)\n",
    "    CleanDF.toPandas().to_csv('sen.csv')\n",
    "    \n",
    "    tw=pd.read_csv(\"sen.csv\")\n",
    "    tw=tw.drop(columns=[\"Unnamed: 0\"])\n",
    "    tw[\"length\"]=\"\"\n",
    "    i=0\n",
    "    # iterate through the csv file \n",
    "    for val in tw[\"Tweets\"]: \n",
    "      val = str(val) \n",
    "      tokens = val.split() \n",
    "      tw[\"length\"][i]=len(tokens)\n",
    "      i=i+1\n",
    "    tw=tw.drop(columns=[\"p_neg\",\"p_neu\",\"p_pos\"])\n",
    "\n",
    "    tw[\"p_comp\"].describe()\n",
    "    mean=tw[\"p_comp\"].mean()\n",
    "    std=tw[\"p_comp\"].std()\n",
    "    tw[\"sentiment\"]=\"\"\n",
    "    i=0\n",
    "    for val in tw[\"p_comp\"]: \n",
    "      if val> mean+2*std:\n",
    "        tw[\"sentiment\"][i]=\"extremely positive\"\n",
    "      if val< mean-2*std:\n",
    "        tw[\"sentiment\"][i]=\"extremely negative\"\n",
    "      if val>mean+std and val<mean+2*std:\n",
    "        tw[\"sentiment\"][i]=\"positive\"\n",
    "      if val<mean-std and val>mean-2*std:\n",
    "        tw[\"sentiment\"][i]=\"negative\"\n",
    "      if val>mean-std and val<mean+std:\n",
    "        tw[\"sentiment\"][i]=\"neutral\"\n",
    "      i=i+1\n",
    "\n",
    "    sentiment=tw.groupby(tw['sentiment']).count().reset_index()\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('2021-1031.csv')\n",
    "tweets = tweets.dropna().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Date_Time</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>p_comp</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>extremely negative</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>1262</td>\n",
       "      <td>1262</td>\n",
       "      <td>1262</td>\n",
       "      <td>1262</td>\n",
       "      <td>1262</td>\n",
       "      <td>1262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>7212</td>\n",
       "      <td>7212</td>\n",
       "      <td>7212</td>\n",
       "      <td>7212</td>\n",
       "      <td>7212</td>\n",
       "      <td>7212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>2308</td>\n",
       "      <td>2308</td>\n",
       "      <td>2308</td>\n",
       "      <td>2308</td>\n",
       "      <td>2308</td>\n",
       "      <td>2308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sentiment  index  Unnamed: 0.1  Date_Time  Tweets  p_comp  length\n",
       "0  extremely negative    319           319        319     319     319     319\n",
       "1            negative   1262          1262       1262    1262    1262    1262\n",
       "2             neutral   7212          7212       7212    7212    7212    7212\n",
       "3            positive   2308          2308       2308    2308    2308    2308"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = sentiment_calculation(tweets)\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11101"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "number.append(len(tweets))\n",
    "extreme_positive.append(0)\n",
    "positive.append(sentiment['Tweets'][3])\n",
    "neutral.append(sentiment['Tweets'][2])\n",
    "negative.append(sentiment['Tweets'][1])\n",
    "extreme_negative.append(sentiment['Tweets'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "number.append(len(tweets))\n",
    "extreme_positive.append(sentiment['Tweets'][1])\n",
    "positive.append(sentiment['Tweets'][4])\n",
    "neutral.append(sentiment['Tweets'][3])\n",
    "negative.append(sentiment['Tweets'][2])\n",
    "extreme_negative.append(sentiment['Tweets'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = [2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_sentiment={\"Year\" : year,\"number\" : number, \"extreme_positive\": extreme_positive, \"positive\": positive,\n",
    "                  \"neutral\": neutral, \"negative\": negative, \"extreme_negative\" : extreme_negative}\n",
    "tweet_sentiment=pd.DataFrame(tweet_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_sentiment['sentiment score'] = tweet_sentiment['extreme_positive']*2+tweet_sentiment['positive']-tweet_sentiment['extreme_negative']*2-tweet_sentiment['negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_sentiment.to_csv('sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('2014-1231.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Tweet Sentiment Analysis and Google Trends Overtime.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
